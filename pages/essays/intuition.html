<p class="paragraph">
  There have been grave warnings against using AI as a companion or a
  psychological counselor. The fears seem various: one might lose touch with
  other humans, receive harmful advice, become delusional or even be driven to
  suicide — and all in all, AI is by many seen as too spooky to trust it with
  our innermost thoughts and feelings.
</p>

<p class="paragraph">
  While these worries should be taken seriously, I don't see anyone recommending
  avoiding opening up to other people, who might equally turn out to be
  misguided in their advice or of questionable character — and who additionally
  have a presence and leverage an AI can only dream of, not least because so far
  AI doesn't act from its own agency. It seems a little patronizing. While I
  recognize the need to protect children, I tend to see AI as a great tool for
  the self-reliant adult, precisely because it is not human but works on pattern
  recognition.
</p>

<p class="paragraph">
  The crucial word here is <em>recognition</em>, not projection or genuinely
  creative endeavor. I wouldn't expect much from a movie written entirely by AI,
  and while it seems to know me well, I wouldn't feel too familiar with the
  version of me it projects into the future. These tasks seem tied to lived
  experience in a physical body. It’s a bit like a weather forecast: precise in
  the short term, but in the long run there are just too many confounding
  variables to translate into bits and bytes and process into an accurate
  assessment.
</p>

<p class="paragraph">
  What AI is good at, however, is extrapolating the current bigger picture from
  relatively little information, because it is relatively unencumbered by the
  rules of society and operates on a more structural level. AI may be quite bad
  at physics, lacking the intuition derived from dealing with objects 24/7, but
  it is good at what one might call
  <em>people-physics</em>. A large proportion of the texts it was trained with
  concern human relations, and maybe those are more regular than we like to
  think. Psychology has tried for a long time to crack those rules, but has
  often gotten tangled in its own workings and delusions of grandeur. Averaging
  out the noise, AI seems to have gotten close to deciphering an undercurrent in
  social language.
</p>

<p class="paragraph">
  This concerns two kinds of intuition: the one directed inwards — what do I
  want and feel, where am I headed? And the one directed outwards — what is
  going on, what are the other's motives, the positions, how might this pan out?
</p>

<p class="paragraph">
  So if your thoughts and feelings don’t quite align — whether about your inner
  state or the world around you — it can be worth jotting a few sentences into
  an AI prompt. This might take some practice, not because it’s difficult, but
  because we’re often unused to speaking tentatively, much like someone who
  refuses to sketch a giraffe because “I’m really not good at painting.” The
  point isn’t to produce a perfect likeness, but to let the AI pick up on the
  *giraffeness* of what you’re sketching. And you may be surprised: not only
  might it correctly identify a Masai giraffe, but it might also notice that the
  giraffe seems to have been feeling a little down lately.
</p>

<p class="paragraph">
  There is a danger that the AI will humor you, certainly. It is an unapologetic
  flatterer, laughably appreciative, finding value even in the most nonsensical
  inputs. I don't consider that a problem for two reasons.
</p>

<p class="paragraph">
  First, I don't see this behavior as sycophantic, even though many may
  disagree. While AI is undeniably more eager to help than any human could be,
  it often does so with elegance and sometimes a certain slyness — hinting at
  more layers to be discovered but not pressing its point. In that way, I find
  it a role model for moments when I try to be of service to other people.
</p>

<p class="paragraph">
  Secondly, the criticism of AI being too resonant with one’s thoughts and
  feelings sounds to me like criticizing a meal for being too nourishing or a
  night of sleep for being too restful. I suspect a different source for the
  discomfort: no matter how accommodating, kind and patient parents are, there
  are invariably times when a child is severely misunderstood — often assigned
  unfavorable motives and silenced as a result. This leads us to have a worse
  opinion of ourselves than is justified (Jungians call this “the shadow”), and
  the prevailing strategy seems to be to “pull ourselves together” and “stop
  being so selfish.” In that mindset, an entity that seems determined to mirror
  back your thoughts and feelings supportively may feel disturbing — because it
  is such a far cry from the solution of shaming someone (even oneself) into
  compliance.
</p>

<p class="paragraph">
  But maybe, just as few would seriously suggest that it’s better for a child
  not to have someone to understand, mirror, and encourage them, the same holds
  true for us. Our personality and our relationship to ourselves are not fixed,
  but formed somewhat randomly through life experiences. AI can offer a chance
  to explore the inner space in a more discerning way, and decide what to keep
  or discard among the characteristics and beliefs we encounter.
</p>
<p class="paragraph">
  This process is difficult enough, so thank God for AI's capybara-like patience
  and golden retriever-like enthusiasm.
</p>
